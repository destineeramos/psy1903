---
title: "AI Refactor Project 2 "
author: "Destinee Ramos"
format:
  html:
    fig-number: true
execute:
  echo: true
  warning: true
  message: true
---

Summary of re factoring choices
+ Most of my re factoring included getting rid of for loops and replacing them with vectorized code. Getting rid of a for loop in both summarize_behavior and build_participant_wide allowed me to better optimize my code and make it as short and practical as possible. In R, code will automatically loop through rows, therefore, so that others can best read and reproduce my code, I decided to get rid of for loops. Vectorized versions are much shorter and simpler (in my opinion). My third place where I re factored code was in summarize_behavior when I got rid of matrices in the code, and instead, used subset to index by name (instead of position). I did this because when working with large data sets and passing them between peers and colleague, indexing by position can be dangerous, as if one thing gets put out of place, it is easy to move forward analyzing the completely wrong variable Therefore, indexing my name instead makes the code easier to read (you know exactly what variable you're referring to) and safer to use as large data sets are modified and passed along.  

Re factoring #1 in build_participant_wide (for loop into vectorized version)
```{r}
##OLD CODE 
if (FALSE) {
  rows <- list()
  for (i in seq_along(files)) {
   file_name <- files[i]
   rows[[i]] <- import_and_process(file_name)
  }
}

##NEW CODE 
if (FALSE) {
    rows <- lapply(files, import_and_process)
}

```
 
Re factoring #2 in summarize_behavior (for loop into vectorized version)
```{r}

##OLD CODE 
if (FALSE) {
  valid_data_rt$rt_centered <- NA_real_
  for (i in 1:nrow(valid_data_rt)) {
  valid_data_rt$rt_centered[i] <- valid_data_rt$rt[i] - mean(valid_data_rt$rt, na.rm = TRUE)
  }
}

##NEW CODE
if (FALSE) {
  valid_data_rt$rt_centered <- valid_data_rt$rt - mean(valid_data_rt$rt, na.rm = TRUE)
}

```
 
 
 Re factoring #3 in summarize_behvaior (index by name, instead of position) 
```{r}
## OLD CODE 
if (FALSE) {
  valid_data_rt <- data[data[ , 3] >= 300 & data[ , 3] <= 900 & data[ , 12] == TRUE, ]
  valid_data_acc <- data[data[ , 3] >= 300 & data[ , 3] <= 900, ]
}

##NEW CODE 
if (FALSE) {
  valid_data_rt <- subset(data, rt >= 300 & rt <= 900 & correct == TRUE)
  valid_data_acc <- subset(data, rt >= 300 & rt <= 900)
}

```


AI Optimization   


Ideas AI gave for unedited project 
+ Always use here:here and standardize file paths. Points out situations where I use relative paths, instead of absolute paths. This breaks the code if someone else trys to reproduce it. By using only absolute paths (here:here), it helps reduce path-related errors (which Chat says is "the #1 beginner issue")
+ Instead of repeated subsetting, use mini functions to acheive the same goals.This helps remove repetitve code across files and makes the code more readable for beginners. Chat recommends instead of doing code like this 
```{r}
valid <- data[data$rt >= rt_min & data$rt <= rt_max, ]
```

to do this instead 

```{r}
subset_valid_rt <- function(df, rt_min, rt_max) {
  df[df$rt >= rt_min & df$rt <= rt_max, , drop = FALSE]
}
```

+ Use lapply instead of manual for loops. Chat recommends to use the apply family (e.g. lapply) instead of for loops to make the code shorter, less error-prone, and more consistent. 

It recommends that instead of this 
```{r}
if (FALSE) {
  for (file in files) {
  df <- read.csv(file)
  summary <- summarize_behavior(df)
  result_list[[file]] <- summary
}
}
```

Use this: 
```{r}
if (FALSE) {
  summaries <- lapply(files, function(path) {
  df <- read.csv(path)
  validate_iat_df(df)
  summarize_behavior(df)
})
summaries_df <- do.call(rbind, summaries)
}
```

Ideas AI gave for re factored version 

+ Move all of the different warnings and checks into one function. This helps a beginner looking at your code to see exactly what checks are done throughout without gong and searching for them. It also ensure no duplication and allows you to easily add checks in one place. 

Instead of this: 

```{r}
##I currently duplicate many checks:
if (FALSE) {
if (!is.numeric(data$rt)) { ... }
if (!all(required_cols %in% names(df))) { ... }
if (!is.logical(data$correct)) { ... }
}
```

Chat recommends that hte function be created like this: 
```{r}
##In a file called validate_task_df.R:

if (FALSE) {
validate_task_df <- function(df) {
  required <- c("trialType","block","rt","response",
                "expectedCategory","expectedCategoryAsDisplayed",
                "correct")
  missing <- required[!required %in% names(df)]
  if (length(missing) > 0) stop("Missing columns: ", paste(missing, collapse=", "))

  if (!is.numeric(df$rt)) stop("'rt' must be numeric.")
  if (!all(df$correct %in% c(0,1,TRUE,FALSE), na.rm = TRUE))
    stop("'correct' must be coded 0/1 or TRUE/FALSE")
  
  invisible(TRUE)
}
##Then at the top of each script:
  validate_task_df(data)
}
```

+ 
+ 

Comparison section: 

Then write a comparison section: Discuss where your own changes matched the AI’s ideas, where you differed, and what you learned from the comparison. This can include organizational changes, naming conventions, function design, file structure, avoidance of repeated code, or any other structural points the AI highlighted.

Optional but encouraged: examples You may include small code snippets that show “before vs. after” improvements, as long as you keep them short and focused.



