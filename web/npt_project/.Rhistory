)
## Save summary CSV to cleaned/participants
write.csv(
df_clean,
file = file.path("data/cleaned/participants", paste0(subject_id, ".csv")),
row.names = FALSE
)
#### Return output ------------------------------------------------------
## Simple check to make sure the summary is one row
stopifnot(nrow(df_clean) == 1)
return(df_clean)
}
#### Processing all participant files ----------------------------------
# Step 1: Find all files
file_list <- list.files("data/raw/", pattern = "*.csv", full.names = TRUE)
# Step 2: Apply the function to each file
all_data <- lapply(file_list, process_participant)
# Step 3: Combine into one data frame
combined <- do.call(rbind, all_data)
warnings()
#### Processing all participant files ----------------------------------
# Step 1: Find all files
file_list <- list.files("data/raw/", pattern = "*.csv", full.names = TRUE)
# Step 2: Apply the function to each file
all_data <- lapply(file_list, process_participant)
# Step 3: Combine into one data frame
combined <- do.call(rbind, all_data)
unique(df$correct)
df
rm(list = ls())
rm(list = ls())
source("scripts/score_questionnaire.R")
rm(list = ls())
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_partcipant.R")
rm(list = ls())
source("scripts/score_questionnaire.R")
rm(list = ls())
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
process_partcipant("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
rm(list = ls())
source("scripts/score_questionnaire.R")
rm(list = ls())
source("scripts/score_questionnaire.R")
source("scripts/summarize_behavior.R")
source("scripts/process_participant.R")
process_participant("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
file.create("npt_group.qmd")
# Load here::here robustly
if (!require(here)) install.packages("here")
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
study_level <- read.csv(here("data/cleaned/study_level.csv"))
if(!require("packman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2")
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
participant_rows <- lapply(file_list, process_participant)
library(jsonlite)
participant_rows <- lapply(file_list, process_participant)
study_level <- do.call(rbind, participant_rows)
study_level <- do.call(rbind, participant_rows)
```{r}
dir.create(".../data/cleaned", recursive = TRUE, showWarnings = FALSE)
write.csv(study_level, "../data/cleaned/study_level.csv", row.names = FALSE)
stopifnot(nrow(study_level) == length(file_list))
head(study_level)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
# Quick inspection
head(study_level)
str(study_level)
summary(study_level)
# Class-level means
colMeans(study_level[, c("magnitude_mean_rt",
"parity_mean_rt",
"rt_diff")],
na.rm = TRUE)
# Quick inspection
head(study_level)
str(study_level)
summary(study_level)
```
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <-
# B) Accuracy difference (complete together)
study_level$acc_diff <-
# C) Overall averages across conditions
study_level$mean_rt_overall  <- rowMeans(
study_level[, c("magnitude_mean_rt", "parity_mean_rt")],
na.rm = TRUE
)
study_level$mean_acc_overall <- rowMeans(
study_level[, c("magnitude_acc", "parity_acc")],
na.rm = TRUE
)
# Peek at the new columns
head(study_level[, c("subject_id", "rt_diff", "acc_diff",
"mean_rt_overall", "mean_acc_overall")])
View(study_level)
library(readr)
df <- read_csv("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
View(df)
if (!all(c("block", "trialType", "trial_type", "rt", "correct") %in% names(df)))
##Change correct column to logical
df$correct <- as.logical(df$correct)
if (!is.numeric(df$rt)) df$rt <- as.numeric(df$rt)
## Separate data into block and trial types
practice_filtered  <- df[df$block == "practice", ]
magnitude_filtered <- df[df$block == "experiment" & df$trial_type == "magnitude", ]
parity_filtered    <- df[df$block == "experiment" & df$trial_type == "parity", ]
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= rt_min &
practice_filtered$rt  <= rt_max, ]
rt_min = 250
rt_max = 900
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= rt_min &
practice_filtered$rt  <= rt_max, ]
magnitude_filtered <- magnitude_filtered[magnitude_filtered$rt >= rt_min &
magnitude_filtered$rt <= rt_max, ]
parity_filtered    <- parity_filtered[parity_filtered$rt    >= rt_min &
parity_filtered$rt    <= rt_max, ]
## Calculate mean reaction time and accuracy for each trial type
practice_mean_rt  <- mean(practice_filtered$rt, na.rm = TRUE)
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
magnitude_mean_rt <- mean(magnitude_filtered$rt, na.rm = TRUE)
magnitude_acc     <- mean(magnitude_filtered$correct, na.rm = TRUE)
parity_mean_rt    <- mean(parity_filtered$rt, na.rm = TRUE)
parity_acc        <- mean(parity_filtered$correct, na.rm = TRUE)
## Calculate standard deviation of reaction times for each trial type
practice_sd_rt  <- sd(practice_filtered$rt, na.rm = TRUE)
magnitude_sd_rt <- sd(magnitude_filtered$rt, na.rm = TRUE)
parity_sd_rt    <- sd(parity_filtered$rt, na.rm = TRUE)
participant_summary <- data.frame(
practice_mean_rt   = practice_mean_rt,
practice_acc       = practice_acc,
magnitude_mean_rt  = magnitude_mean_rt,
magnitude_acc      = magnitude_acc,
parity_mean_rt     = parity_mean_rt,
parity_acc         = parity_acc,
practice_sd_rt     = practice_sd_rt,
magnitude_sd_rt    = magnitude_sd_rt,
parity_sd_rt       = parity_sd_rt,
stringsAsFactors   = FALSE
)
# Check that accuracy is between 0 and 1
acc_cols <- c("practice_acc", "magnitude_acc", "parity_acc")
for (col in acc_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < 0 || val > 1)) {
warning(paste(col, "is outside the range [0, 1]. Check 'correct' coding."))
}
}
# Check that mean RTs are within the expected range
rt_cols <- c("practice_mean_rt", "magnitude_mean_rt", "parity_mean_rt")
for (col in rt_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < rt_min || val > rt_max)) {
warning(paste(col, "is outside the expected range [", rt_min, ",", rt_max, "]."))
}
}
return(participant_summary)
View(participant_summary)
tef10_score <- score_questionnaire(
json_string = df[df$trialType == "questionnaire", "response"],
reverse= c(2, 4, 7),
scale_min = 0L,
scale_max = 4L
)
df[df$trialType == "questionnaire", "response"]
responses <- jsonlite::fromJSON(df[df$trialType == "questionnaire", "response"])
responses <- jsonlite::fromJSON(as.character(df[df$trialType == "questionnaire", "response"]))
library(readr)
df <- read_csv("data/raw/npt-experiment-2025-11-05-10-33-05.csv")
View(df)
df <- read.csv("data/raw/npt-experiment-2025-11-05-10-33-05.csv", stringsAsFactors = FALSE)
str(df)
responses <- jsonlite::fromJSON(df[df$trialType == "questionnaire", "response"])
## 2) Flatten and convert to numeric
##    Use unlist() to turn the list into a vector and coerce to numeric if needed.
## Example:
responses <- as.numeric(unlist(responses))
# If reverse is provided, it must reference valid item positions
if (length(reverse) > 0) {
if (any(reverse < 1 | reverse > length(responses))) {
stop("One or more 'reverse' item indices are out of range for this questionnaire response.")
}
}
## 5) Compute the final score
mean_score <- mean(responses, na.rm = TRUE)
if(!require("packman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2")
install.packages("jsonlite")   # only run once
library(jsonlite)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
participant_rows <- lapply(file_list, process_participant)
View(participant_rows)
study_level <- do.call(rbind, participant_rows)
View(study_level)
df <- read.csv("data/raw/npt-experiment-2025-11-05-10-33-05.csv", stringsAsFactors = FALSE)
str(df)
df$correct <- as.logical(df$correct)
str(df)
## Separate data into block and trial types
practice_filtered  <- df[df$block == "practice", ]
magnitude_filtered <- df[df$block == "experiment" & df$trial_type == "magnitude", ]
parity_filtered    <- df[df$block == "experiment" & df$trial_type == "parity", ]
## Filter out unreasonable reaction times (keep 250–900 ms)
practice_filtered  <- practice_filtered[practice_filtered$rt  >= rt_min &
practice_filtered$rt  <= rt_max, ]
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
practice_acc
magnitude_mean_rt <- mean(magnitude_filtered$rt, na.rm = TRUE)
magnitude_acc     <- mean(magnitude_filtered$correct, na.rm = TRUE)
parity_mean_rt    <- mean(parity_filtered$rt, na.rm = TRUE)
parity_acc        <- mean(parity_filtered$correct, na.rm = TRUE)
magnitude_acc
parity_acc
## Calculate standard deviation of reaction times for each trial type
practice_sd_rt  <- sd(practice_filtered$rt, na.rm = TRUE)
magnitude_sd_rt <- sd(magnitude_filtered$rt, na.rm = TRUE)
parity_sd_rt    <- sd(parity_filtered$rt, na.rm = TRUE)
## Calculate mean reaction time and accuracy for each trial type
practice_mean_rt  <- mean(practice_filtered$rt, na.rm = TRUE)
practice_acc      <- mean(practice_filtered$correct, na.rm = TRUE)
magnitude_mean_rt <- mean(magnitude_filtered$rt, na.rm = TRUE)
magnitude_acc     <- mean(magnitude_filtered$correct, na.rm = TRUE)
parity_mean_rt    <- mean(parity_filtered$rt, na.rm = TRUE)
parity_acc        <- mean(parity_filtered$correct, na.rm = TRUE)
participant_summary <- data.frame(
practice_mean_rt   = practice_mean_rt,
practice_acc       = practice_acc,
magnitude_mean_rt  = magnitude_mean_rt,
magnitude_acc      = magnitude_acc,
parity_mean_rt     = parity_mean_rt,
parity_acc         = parity_acc,
practice_sd_rt     = practice_sd_rt,
magnitude_sd_rt    = magnitude_sd_rt,
parity_sd_rt       = parity_sd_rt,
stringsAsFactors   = FALSE
)
participant_summary
# Check that accuracy is between 0 and 1
acc_cols <- c("practice_acc", "magnitude_acc", "parity_acc")
for (col in acc_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < 0 || val > 1)) {
warning(paste(col, "is outside the range [0, 1]. Check 'correct' coding."))
}
}
# Check that mean RTs are within the expected range
rt_cols <- c("practice_mean_rt", "magnitude_mean_rt", "parity_mean_rt")
for (col in rt_cols) {
val <- participant_summary[[col]]
if (!is.na(val) && (val < rt_min || val > rt_max)) {
warning(paste(col, "is outside the expected range [", rt_min, ",", rt_max, "]."))
}
}
View(participant_summary)
tef10_score <- score_questionnaire(
json_string = df[df$trialType == "questionnaire", "response"],
reverse= c(2, 4, 7),
scale_min = 0L,
scale_max = 4L
)
tef10_score
subject_id <- "npt-experiment-2025-11-05-10-33-05"
## Combine into a single-row participant summary
df_clean <- data.frame (
subject_id = subject_id,
tef10_score = tef10_score,
behavior = behavior
)
behavior <- summarize_behavior(df, rt_min = 250, rt_max = 900)
View(behavior)
## Combine into a single-row participant summary
df_clean <- data.frame (
subject_id = subject_id,
tef10_score = tef10_score,
behavior = behavior
)
View(df_clean)
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
participant_rows <- lapply(file_list, process_participant)
if(!require("packman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2")
install.packages("jsonlite")   # only run once
library(jsonlite)
file_list <- list.files("../data/raw", pattern = "^npt-experiment-.*\\.csv$", full.names = TRUE)
participant_rows <- lapply(file_list, process_participant)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
participant_rows <- lapply(file_list, process_participant)
participant_rows <- lapply(file_list, process_participant)
participant_rows <- lapply(file_list, process_participant)
participant_rows <- lapply(file_list, process_participant)
traceback()
score_questionnaire(df[df$trial_type == "questionnaire", "response"])
View(df)
score_questionnaire(df[df$trialType == "questionnaire", "response"])
summarize_behavior(df, rt_min = 250, rt_max = 900)
bad_files <- sapply(file_list, function(f) {
df <- read.csv(f, stringsAsFactors = FALSE)
any(!df$correct %in% c("True", "False", ""))
})
library(here)
bad_files <- sapply(file_list, function(f) {
df <- read.csv(here::here("data", "raw", f), stringsAsFactors = FALSE)
any(!df$correct %in% c("True", "False", ""))
})
bad_files <- sapply(file_list, function(f) {
df <- read.csv(f, stringsAsFactors = FALSE)  # just use f directly
any(!df$correct %in% c("True", "False", ""))
})
getwd()
if(!require("packman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2")
install.packages("jsonlite")   # only run once
library(jsonlite)
if(!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2")
install.packages("jsonlite")   # only run once
library(jsonlite)
p_load("jsonlite", "ggplot2", "here")
if(!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2", "here")
#install.packages("jsonlite")   # only run once
#library(jsonlite)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
file_list <- list.files(
here::here("data", "raw"),
pattern = "^npt-experiment-.*\\.csv$",
full.names = FALSE
)
participant_rows <- lapply(file_list, process_participant)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
file_list <- list.files(
here::here("data", "raw"),
pattern = "^npt-experiment-.*\\.csv$",
full.names = FALSE
)
participant_rows <- lapply(file_list, process_participant)
traceback()
file_list
participant_rows <- lapply(file_list, process_participant)
traceback()
if (!all(c("block", "trialType", "trial_type", "rt", "correct") %in% names(df)))
{}
!all(c("block", "trialType", "trial_type", "rt", "correct") %in% names(df))
str(df$correct)
df$correct <- as.character(df$correct)
!all(c("block", "trialType", "trial_type", "rt", "correct") %in% names(df))
if (!all(c("block", "trialType", "trial_type", "rt", "correct") %in% names(df))) {
##Change correct column to logical
df$correct <- as.logical(df$correct)
}
str(df$correct)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
file_list <- list.files(
here::here("data", "raw"),
pattern = "^npt-experiment-.*\\.csv$",
full.names = FALSE
)
participant_rows <- lapply(file_list, process_participant)
traceback()
study_level <- do.call(rbind, participant_rows)
View(study_level)
if(!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2", "here")
#install.packages("jsonlite")   # only run once
#library(jsonlite)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
file_list <- list.files(
here::here("data", "raw"),
pattern = "^npt-experiment-.*\\.csv$",
full.names = FALSE
)
participant_rows <- lapply(file_list, process_participant)
traceback()
if(!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2", "here")
#install.packages("jsonlite")   # only run once
#library(jsonlite)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
file_list <- list.files(
here::here("data", "raw"),
pattern = "^npt-experiment-.*\\.csv$",
full.names = FALSE
)
participant_rows <- lapply(file_list, process_participant)
traceback()
View(participant_rows)
study_level <- do.call(rbind, participant_rows)
View(study_level)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <-
# B) Accuracy difference (complete together)
study_level$acc_diff <-
# C) Overall averages across conditions
study_level$mean_rt_overall  <- rowMeans(
study_level[, c("magnitude_mean_rt", "parity_mean_rt")],
na.rm = TRUE
)
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
# Quick inspection
head(study_level)
str(study_level)
summary(study_level)
## Replace Column Names
names(study_level) <- c("subject_id", "tef10_score", "practice_mean_rt", "practice_acc", "magnitude_mean_rt", "magnitude_acc", "parity_mean_rt", "parity_acc", "practice_sd_rt", "magnitude_sd_rt", "parity_sd_rt")
write.csv(study_level, here::here("data/cleaned/study_level.csv"), row.names = FALSE)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <-
# B) Accuracy difference (complete together)
study_level$acc_diff <-
# C) Overall averages across conditions
study_level$mean_rt_overall  <- rowMeans(
study_level[, c("magnitude_mean_rt", "parity_mean_rt")],
na.rm = TRUE
)
View(study_level)
if(!require("pacman")) {install.packages("pacman"); require("pacman")}
p_load("jsonlite", "ggplot2", "here")
#install.packages("jsonlite")   # only run once
#library(jsonlite)
source("../scripts/score_questionnaire.R")
source("../scripts/summarize_behavior.R")
source("../scripts/process_participant.R")
file_list <- list.files(
here::here("data", "raw"),
pattern = "^npt-experiment-.*\\.csv$",
full.names = FALSE
)
participant_rows <- lapply(file_list, process_participant)
traceback()
study_level <- do.call(rbind, participant_rows)
dir.create(".../data/cleaned", recursive = TRUE, showWarnings = FALSE)
write.csv(study_level, "../data/cleaned/study_level.csv", row.names = FALSE)
saveRDS(study_level, "../data/cleaned/study_level.rds")
stopifnot(nrow(study_level) == length(file_list))
head(study_level)
# Load here::here robustly
if (!require(here)) install.packages("here")
library(here)
# Load the study-level dataset built in our previous workflow
study_level <- read.csv(here("data/cleaned/study_level.csv"))
# Quick inspection
head(study_level)
str(study_level)
summary(study_level)
names(study_level)
## Replace Column Names
names(study_level) <- c("subject_id", "tef10_score", "practice_mean_rt", "practice_acc", "magnitude_mean_rt", "magnitude_acc", "parity_mean_rt", "parity_acc", "practice_sd_rt", "magnitude_sd_rt", "parity_sd_rt")
write.csv(study_level, here::here("data/cleaned/study_level.csv"), row.names = FALSE)
# A) Reaction time difference (complete this line together)
# hint: subtract magnitude mean RT from parity mean RT
study_level$rt_diff <-
# B) Accuracy difference (complete together)
study_level$acc_diff <-
# C) Overall averages across conditions
study_level$mean_rt_overall  <- rowMeans(
study_level[, c("magnitude_mean_rt", "parity_mean_rt")],
na.rm = TRUE
)
View(study_level)
getwd()
setwd(../Users/destineeramos/Desktop/psy1903/web)
setwd("/Users/destineeramos/Desktop/psy1903/web")
dir.create("codechatpractice", recursive = TRUE)
dir.create("codechatpractice/data/raw", recursive = TRUE)
dir.create("codechatpractice/data/cleaned", recursive = TRUE)
dir.create("codechatpractice/scripts", recursive = TRUE)
dir.create("codechatpractice/reports", recursive = TRUE)
